{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MartinVoelkl94/Python_compendium/blob/main/mv_functions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aEh9H_mViNsg"
      },
      "source": [
        "contains utility functions.\n",
        "\n",
        "mv_functions.ipynb is meant to be used for looking up, editing or adding functions while mv_functions.py is used to import functions to other scripts or notebooks (use 'import mv_functions as mv').\n",
        "\n",
        "The last cell of mv_functions.ipynb contains code that backs up the current mv_functions.py file and converts mv_functions.ipynb into a new mv_functions.py."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ndcqlRcFiNsi"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import types\n",
        "import time\n",
        "import shutil\n",
        "import os\n",
        "import sys\n",
        "import pickle\n",
        "import datetime\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#this part is not meant to be executed after conversion to a .py file\n",
        "if 'colab' in get_ipython().config['IPKernelApp']['kernel_class']:\n",
        "    # mounting to drive folder\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "    #acces functions from mv_functions.py\n",
        "    sys.path.append('/content/drive/MyDrive/coding/Python/Compendium')\n",
        "    os.chdir('/content/drive/MyDrive/coding/Python/Compendium')\n",
        "    import mv_functions as mv"
      ],
      "metadata": {
        "id": "KdnCVqcw7Z8F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tree(data, name='data', indent='|   '):\n",
        "    \"\"\"\n",
        "    gives a condensed overview of the content of an object in a form resembling\n",
        "    a folder tree. Made to be used in data exploration or when investigating a \n",
        "    new algorithm. It has similar usecases as the basic type() function but in \n",
        "    addition it also gives more information on certain common data types an is\n",
        "    able to show multiple layers of nested objects.\n",
        "\n",
        "    Parameters:\n",
        "    data: an object identifiable ny type()\n",
        "    name: optional. the name of the current object\n",
        "    indent: used to modify visual presentation of the output\n",
        "\n",
        "    Returns:\n",
        "    prints to output instead of returning\n",
        "    \"\"\"\n",
        "    name = [name]\n",
        "    level = 0  #tracks progress through layers of nested objects\n",
        "    _tree_check_type(data, name, level, indent)   \n",
        "    \n",
        "\n",
        "def _tree_check_type(current_data, name, level, indent):\n",
        "    #used by tree function to check the type of current_data\n",
        "\n",
        "    indents = level*indent\n",
        "    current_data_name = ''.join(name)\n",
        "    \n",
        "    #the following if-statements check for common data types and then go a\n",
        "    #level deeper when encountering a list, dict, array or dataframe\n",
        "    if isinstance(current_data, list):\n",
        "        if level == 0:\n",
        "            print(f'{indents}list:')\n",
        "        else:\n",
        "            print(f'{indents}list: {current_data_name}')\n",
        "        level += 1\n",
        "        _tree_open_list(current_data, name, level, indent)\n",
        "\n",
        "    elif isinstance(current_data, dict):\n",
        "        if level == 0:\n",
        "            print(f'{indents}dictionary:')\n",
        "        else:\n",
        "            print(f'{indents}dictionary: {current_data_name}')\n",
        "        level += 1\n",
        "        _tree_open_dict(current_data, name, level, indent)\n",
        "\n",
        "    elif isinstance(current_data, np.ndarray):\n",
        "        if level == 0:\n",
        "            print(f'{indents}np.ndarray:')\n",
        "        else:\n",
        "            print(f'{indents}np.ndarray: {current_data_name}')\n",
        "        level += 1\n",
        "        _tree_open_np_ndarray(current_data, name, level, indent)\n",
        "    \n",
        "    elif isinstance(current_data, pd.core.frame.DataFrame):\n",
        "        if level == 0:\n",
        "            print(f'{indents}dataframe:')\n",
        "        else:\n",
        "            print(f'{indents}dataframe: {current_data_name}')\n",
        "        level += 1\n",
        "        _tree_open_pd_dataframe(current_data, name, level, indent)\n",
        "    \n",
        "    else:\n",
        "        print(f'{indents}{str(type(current_data))[8:-2]}')\n",
        "\n",
        "\n",
        "def _tree_open_list(current_data, name, level, indent):\n",
        "    #used by tree function to open and display contents of lists.\n",
        "\n",
        "    counter = {}\n",
        "    for ind in range(len(current_data)):\n",
        "        if str(type(current_data[ind]))[8:-2] in counter.keys():\n",
        "            counter[str(type(current_data[ind]))[8:-2]] += 1\n",
        "        else:\n",
        "            counter[str(type(current_data[ind]))[8:-2]] = 1\n",
        "    \n",
        "    for key in counter.keys():\n",
        "        print(f'{level*indent}{key}: {counter[key]} times')\n",
        "\n",
        "\n",
        "def _tree_open_dict(current_data, name, level, indent):\n",
        "    #used by tree function to open and display contents of dictionaries.\n",
        "\n",
        "    for key in current_data.keys():\n",
        "        if isinstance(key, str):\n",
        "            name.append(f'[\"{key}\"]')\n",
        "        else:\n",
        "            name.append(f'[{str(key)}]')\n",
        "        _tree_check_type(current_data[key], name, level, indent)\n",
        "        name.pop()\n",
        "\n",
        "\n",
        "def _tree_open_np_ndarray(current_data, name, level, indent):\n",
        "    #used by tree function to open and display contents of numpy arrays.\n",
        "\n",
        "    current_data_name = ''.join(name)\n",
        "    \n",
        "    if current_data.shape[0] == 1:\n",
        "        cols = f'[0,0:{len(current_data[0,:])}]'\n",
        "        print(f'{level*indent}1 col: {current_data_name}[0,:]')\n",
        "        print(f'{level*indent}{len(current_data[0,:])} rows: {current_data_name}{cols}')\n",
        "        \n",
        "    elif current_data.shape[0] >= 2:\n",
        "        rows = f'[0:{len(current_data[:,0])},:]'\n",
        "        print(f'{level*indent}{len(current_data[:,0])} rows: {current_data_name}{rows}')\n",
        "        \n",
        "        cols = f'[:,0:{len(current_data[0,:])}]'\n",
        "        print(f'{level*indent}{len(current_data[0,:])} cols: {current_data_name}{cols}')\n",
        "        \n",
        "    else:\n",
        "        print(f'{level*indent}shape: {current_data.shape}')\n",
        "\n",
        "\n",
        "def _tree_open_pd_dataframe(current_data, name, level, indent):\n",
        "    #used by tree function to open and display contents of pandas dataframes.\n",
        "\n",
        "    for colname in list(current_data):\n",
        "        current_data_name = ''.join(name)\n",
        "        n_values = len(current_data[colname])\n",
        "        if isinstance(colname, str):\n",
        "            print(f'{level*indent}{n_values} values in:{current_data_name}[\"{colname}\"]')\n",
        "        else:\n",
        "            print(f'{level*indent}{n_values} values in: {current_data_name}[{colname}]')"
      ],
      "metadata": {
        "id": "a1rPDk3T01TW"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save(data, path=None, readme='no readme found',\n",
        "         supp={}, overwrite=False, verbose=True):\n",
        "    \"\"\"\n",
        "    Makes working with various objects a little faster and more convenient.\n",
        "    Not meant for use in production ready code. Saves any type of python object\n",
        "    thats compatible with the pickle library as a file while offering some\n",
        "    additional convenience:\n",
        "        -one function for all data types\n",
        "        -therefore can be used when type of output is unknown beforehand\n",
        "        -option to include a readme string to explain the data\n",
        "        -option to include additional supplementary data\n",
        "        -if chosen or default (data0.pkl) filename already exists it increments\n",
        "            the number in the filename instead of overwriting the old file\n",
        "\n",
        "    Parameters:\n",
        "    data: any object compatible with the pickle library.\n",
        "    path: optional. filename or filepath to save the data as. if none is\n",
        "        provided, the data is saved in the current folder as data0.pkl.\n",
        "        if the chosen or default name is already taken, ascending numbers\n",
        "        (up to 1000) are added until the name is valid. its not necessary\n",
        "        (but possible) to add the '.pkl' extension when calling the function.\n",
        "    readme: optional. a string that can be saved with the data, for example\n",
        "        to explain where the data came from or how it was generated.\n",
        "        when loading the data   with the corresponding function mv.load the\n",
        "        string can be recalled.\n",
        "    supp: optional. a dictionary containing any additional object/s to be saved\n",
        "        together with the main data, for example the source of the data or the\n",
        "        code that produced it.\n",
        "    overwrite: whether or not existing files should be overwritten if they\n",
        "        have the same name as the one chosen for the data to save.\n",
        "    verbose: if confirmation and location of the saved file should be printed\n",
        "    \"\"\"\n",
        "\n",
        "    if path == None: #neither directory nor filename provided\n",
        "        filename = 'data'\n",
        "        directory = os.getcwd()\n",
        "\n",
        "    elif '/' in path:  #directory provided\n",
        "        directory = '/'.join(path.split('/')[:-1])\n",
        "        if path.split('/')[-1] == '':  #directory provided but no filename\n",
        "            filename = 'data'\n",
        "        else:  #directory and filename provided\n",
        "            filename = path.split('/')[-1]\n",
        "\n",
        "    else:  #filename provided but no directory\n",
        "        directory = os.getcwd()\n",
        "        filename = path\n",
        "\n",
        "    #cut of extension (if one is given)\n",
        "    filename = filename.split('.')[0]\n",
        "\n",
        "    #put data, readme and supplements into dictionary\n",
        "    save_dict = {'data': data, 'readme': readme, 'supplementary': supp}\n",
        "\n",
        "    #set path to save data in ignoring existing files with that name\n",
        "    if overwrite == True:\n",
        "        save_path = f'{directory}/{filename}.pkl'\n",
        "    #increment filenumber as to not overwrite existing files instead\n",
        "    else:\n",
        "        existing_filenames = os.listdir(directory)\n",
        "        for i in range(1000):\n",
        "            save_name = f'{filename}{str(i)}.pkl'\n",
        "            if save_name not in existing_filenames:\n",
        "                save_path = f'{directory}/{save_name}'\n",
        "                break\n",
        "\n",
        "    #save data\n",
        "    with open(save_path, 'wb') as file:\n",
        "        pickle.dump(save_dict, file)\n",
        "        if verbose:\n",
        "            print('data saved in: ', save_path)\n",
        "\n",
        "\n",
        "\n",
        "def load(path='data0', readme=False, supp=False, verbose=False):\n",
        "    \"\"\"\n",
        "    loads objects saved with mv.save.\n",
        "\n",
        "    Parameters:\n",
        "    path: optional. filename or filepath of the object to load. if non is given,\n",
        "        the default path of mv.save (data0.pkl) is used.\n",
        "    readme: wether to load the readme string saved with the object\n",
        "    supp: wether to load the dictionary of supplements saved with the object\n",
        "    verbose: switches 'commentary' on or off\n",
        "    \"\"\"\n",
        "    \n",
        "    if '.pkl' not in path and '.pckl' not in path:\n",
        "        path = f'{path}.pkl'\n",
        "\n",
        "    with open(path, 'rb') as file:\n",
        "        save_dict = pickle.load(file)\n",
        "        \n",
        "    if readme:\n",
        "        print('readme:\\n', save_dict['readme'])\n",
        "        \n",
        "    if supp:\n",
        "        if verbose:\n",
        "            print('supplementary information loaded from: ', path)\n",
        "        return(save_dict['supplementary'])\n",
        "    else:\n",
        "        if verbose:\n",
        "            print('data without supplementary information loaded from: ', path)\n",
        "        return(save_dict['data'])"
      ],
      "metadata": {
        "id": "AlUe3D9gSMC7"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ned15R0iNsr",
        "outputId": "fe3655ee-b3ac-49c7-e468-b136246d0c4d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "saving old mv_functions file as: mv_functions_saves/2023-04-01 13:27:13.166754.py\n",
            "[NbConvertApp] Converting notebook mv_functions.ipynb to script\n",
            "[NbConvertApp] Writing 10582 bytes to mv_functions.py\n"
          ]
        }
      ],
      "source": [
        "#this code backs up the current mv_functions.py file and converts \n",
        "#mv_functions.ipynb into a new mv_functions.py.\n",
        "#lastly it deletes the lines containing itself from the file.\n",
        "\n",
        "os.chdir('/content/drive/MyDrive/coding/Python/Compendium')\n",
        "if os.path.exists('mv_functions.py'):\n",
        "  save_path = f'mv_functions_saves/{datetime.datetime.now()}.py'\n",
        "  shutil.copy('mv_functions.py', save_path)\n",
        "  print(f'saving old mv_functions file as: {save_path}')\n",
        "\n",
        "!jupyter nbconvert --to script mv_functions.ipynb\n",
        "\n",
        "with open('mv_functions.py', 'r') as file:\n",
        "    text = file.readlines()\n",
        "with open('mv_functions.py', 'w') as file:\n",
        "    file.write('#this file was created from mv_functions.ipynb using nbconvert\\n')\n",
        "    for line in text[0:-21]:  \n",
        "        file.write(line)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}